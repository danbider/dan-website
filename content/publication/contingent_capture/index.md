---
title: "Contingent Capture Is Weakened in Search for Multiple Features From Different Dimensions"

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - admin
  - Natalie Biderman
  - Alon Zivony
  - Dominique Lamy

# Author notes (optional)
author_notes:
  - "Equal contribution"
  - "Equal contribution"

date: "2017-04-20T00:00:00Z"
doi: ""

# Schedule page publish date (NOT publication's date).
publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["2"]

# Publication name and optional abbreviated publication name.
publication: In *Journel of Experimental Psychology -- Human Perception and Performance*
publication_short: In *JEP HPP*

abstract: Can observers maintain more than 1 attentional set and search for 2 features in parallel? Previous studiesthat relied on attentional capture by irrelevant distractors to answer this question focused on features from the same dimension and specifically, on color. They showed that 2 separate color templates can guide attention selectively and simultaneously. Here, the authors investigated attentional guidance by 2 features from different dimensions. In three spatial-cueing experiments, they compared contingent capture during single-set versus dual-set search. The results showed that attention was guided less efficiently by 2 features than by just 1. This impairment varied considerably across target-feature dimensions (color, size, shape and orientation). Confronted with previous studies, our findings suggest avenues for future research to determine whether impaired attentional guidance by multiple templates occurs only in cross-dimensional disjunctive search or also in within-dimension search. The present findings also showed that although performance improved when the target feature repeated on successive trials, a relevant-feature cue did not capture attention to a larger extent when its feature matched that of the previous target. These findings suggest that selection history cannot account for contingent capture and affects processes subsequent to target selection.

# Summary. An optional shortened abstract.
summary: A series of visual-serach experiments asking people to search for multiple features in parallel while ignoring distractors. The pattern of people's attentional capture allowed us to characterize the cost of multi-tasking.

tags: []

# Display this page in the Featured widget?
featured: false

# Custom links (uncomment lines below)
# links:
# - name: Talk
#   url: https://slideslive.com/38959632/

url_pdf: ""
url_code: ""
url_dataset: ""
url_poster: ""
url_project: ""
url_slides: ""
url_source: "https://pubmed.ncbi.nlm.nih.gov/28425733/"
url_video: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: "Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)"
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---

{{% callout note %}}
Click the _Cite_ button above to demo the feature to enable visitors to import publication metadata into their reference management software.
{{% /callout %}}

{{% callout note %}}
Create your slides in Markdown - click the _Slides_ button to check out the example.
{{% /callout %}}

Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/).
